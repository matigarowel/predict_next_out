{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORT_COUNT = 3990000\n",
    "TEST_COUNT = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed is: 71926\n"
     ]
    }
   ],
   "source": [
    "# Generate random seed\n",
    "#myrand=np.random.randint(1, 99999 + 1)\n",
    "myrand=71926\n",
    "np.random.seed(myrand)\n",
    "tf.random.set_seed(myrand)\n",
    "print(\"Random seed is:\",myrand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREVIOUS_TIMESTEP_COUNT = 4\n",
    "TOTAL_DATA_NUM = IMPORT_COUNT-PREVIOUS_TIMESTEP_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the sequence of generated numbers to 4 inputs and one output\n",
    "def strided(a, L):\n",
    "\tshp = a.shape\n",
    "\ts  = a.strides\n",
    "\tnd0 = shp[0]-L+1\n",
    "\tshp_in = (nd0,L)+shp[1:]\n",
    "\tstrd_in = (s[0],) + s\n",
    "\treturn np.lib.stride_tricks.as_strided(a, shape=shp_in, strides=strd_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   135410    110121      8382 ... 349829997 526269998 489439999]\n"
     ]
    }
   ],
   "source": [
    "HD_OUTPUT_FILENAME=\"hashdice.txt\"\n",
    "df = np.genfromtxt(HD_OUTPUT_FILENAME,delimiter='\\n',dtype='uint64')[:IMPORT_COUNT]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# calculates how many bits are in the output.\n",
    "BIT_WIDTH = np.ceil(np.log2(np.amax(df))).astype(int)\n",
    "print(BIT_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the generated numbers to binary sequences\n",
    "df_as_bits =(df[:,None] & (1 << np.arange(BIT_WIDTH,dtype='uint64')) > 0).astype(int)\n",
    "df_as_frames = strided(df_as_bits, PREVIOUS_TIMESTEP_COUNT+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies = np.arange(TOTAL_DATA_NUM,dtype='uint64')\n",
    "np.random.shuffle(indicies)\n",
    "df_as_frames=df_as_frames[indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 0 1 1 0 1 0 1 0\n",
      " 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0\n",
      " 0 1 1 0 1 1 0 0 0]\n",
      "[1 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# convert the data into inputs and outputs\n",
    "y = df_as_frames[:,-1,:]\n",
    "X = df_as_frames[:,:-1,]\n",
    "X = X.reshape([X.shape[0], X.shape[1]*X.shape[2]])\n",
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into train and test data\n",
    "X_train = X[TEST_COUNT:]\n",
    "X_test = X[:TEST_COUNT]\n",
    "y_train = y[TEST_COUNT:]\n",
    "y_test = y[:TEST_COUNT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\tLOSS=\"binary_crossentropy\"\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(2000, activation='relu',input_shape=[X.shape[1]] ))\n",
    "\tmodel.add(Dense(1024, activation='relu'))\n",
    "\tmodel.add(Dense(512, activation='relu'))\n",
    "\tmodel.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "\topt = keras.optimizers.Nadam(\n",
    "\t\tlearning_rate=hp.Float(\"learning_rate\", 10**(-5), 10**(-3),sampling=\"log\"),\n",
    "\t\tepsilon=hp.Float(\"epsilon\",1e-7,1e-5,sampling=\"log\"),\n",
    "\t\tbeta_1=hp.Float(\"beta_1\",.8,.9,sampling=\"reverse_log\"),\n",
    "\t\tbeta_2=hp.Float(\"beta_2\",.8,.9,sampling=\"reverse_log\"),\n",
    "\t\t)\n",
    "\tmodel.compile(optimizer=opt, loss=LOSS,metrics=['binary_accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define call back functions\n",
    "stopEarly = tf.keras.callbacks.EarlyStopping(\n",
    "\tmonitor='binary_accuracy', min_delta=.001, patience=3, verbose=0, mode='auto', restore_best_weights=False\n",
    ")\n",
    "\n",
    "log_dir = \"hyperparameters/\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,profile_batch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a short set from the training for hyper parameter tuning\n",
    "X_train_short= X_train[:600000]\n",
    "y_train_short= y_train[:600000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [06h 05m 26s]\n",
      "binary_accuracy: 0.6350803375244141\n",
      "\n",
      "Best binary_accuracy So Far: 0.7840414047241211\n",
      "Total elapsed time: 06h 05m 26s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in .\\bayes\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x00000211A9A43DF0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001648110393164771\n",
      "epsilon: 5.21274252902935e-07\n",
      "beta_1: 0.8623296722989229\n",
      "beta_2: 0.8178901768890696\n",
      "Score: 0.7840414047241211\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001871037160927886\n",
      "epsilon: 1.1351280272965006e-06\n",
      "beta_1: 0.8872810391566094\n",
      "beta_2: 0.8832777157779522\n",
      "Score: 0.755042314529419\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 1.6488459782411778e-05\n",
      "epsilon: 9.909288682697074e-07\n",
      "beta_1: 0.8358150404621888\n",
      "beta_2: 0.8761887649028919\n",
      "Score: 0.6350803375244141\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 1.350549298605751e-05\n",
      "epsilon: 1.1855368435475223e-07\n",
      "beta_1: 0.834350775825664\n",
      "beta_2: 0.8327215039991729\n",
      "Score: 0.6232026219367981\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0009398092893962062\n",
      "epsilon: 1.1554936600263672e-07\n",
      "beta_1: 0.8996103750712536\n",
      "beta_2: 0.8888579020632212\n",
      "Score: 0.5773335695266724\n",
      "CPU times: total: 18h 2min 46s\n",
      "Wall time: 6h 5min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tuning the hyper parameters\n",
    "\n",
    "tuner = kt.tuners.bayesian.BayesianOptimization(build_model,'binary_accuracy',5,project_name=\"bayes\", seed=myrand)\n",
    "tuner.search(X_train_short, y_train_short,batch_size=256, epochs=100, validation_data=(X_test,y_test),callbacks=[stopEarly,tensorboard_callback])\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0001648110393164771,\n",
       " 'epsilon': 5.21274252902935e-07,\n",
       " 'beta_1': 0.8623296722989229,\n",
       " 'beta_2': 0.8178901768890696}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "# use the best model for training\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X = X_train, Y=y_train, epochs=10, batch_size=512,verbose=0, log_dir = f\"dense_model/\"):\n",
    "    log_dir += datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,profile_batch=0)\n",
    "    model.fit(X, Y, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size,callbacks=[tensorboard_callback],verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "my_model_trained = train_model(model, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test, batch_size=256)\n",
    "print(\"test loss: %f, test acc: %s\" % tuple(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_trained.save(\"hashdice_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
