{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORT_COUNT = 2990000\n",
    "TEST_COUNT = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed is: 71926\n"
     ]
    }
   ],
   "source": [
    "# Generate random seed\n",
    "#myrand=np.random.randint(1, 99999 + 1)\n",
    "myrand=71926\n",
    "np.random.seed(myrand)\n",
    "tf.random.set_seed(myrand)\n",
    "print(\"Random seed is:\",myrand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREVIOUS_TIMESTEP_COUNT = 4\n",
    "TOTAL_DATA_NUM = IMPORT_COUNT-PREVIOUS_TIMESTEP_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the sequence of generated numbers to 4 inputs and one output\n",
    "def strided(a, L):\n",
    "\tshp = a.shape\n",
    "\ts  = a.strides\n",
    "\tnd0 = shp[0]-L+1\n",
    "\tshp_in = (nd0,L)+shp[1:]\n",
    "\tstrd_in = (s[0],) + s\n",
    "\treturn np.lib.stride_tricks.as_strided(a, shape=shp_in, strides=strd_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   135410    110121      8382 ... 578769997  48499998 494499999]\n"
     ]
    }
   ],
   "source": [
    "HD_OUTPUT_FILENAME=\"hashdice.txt\"\n",
    "df = np.genfromtxt(HD_OUTPUT_FILENAME,delimiter='\\n',dtype='uint64')[:IMPORT_COUNT]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# calculates how many bits are in the output.\n",
    "BIT_WIDTH = np.ceil(np.log2(np.amax(df))).astype(int)\n",
    "print(BIT_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the generated numbers to binary sequences\n",
    "df_as_bits =(df[:,None] & (1 << np.arange(BIT_WIDTH,dtype='uint64')) > 0).astype(int)\n",
    "df_as_frames = strided(df_as_bits, PREVIOUS_TIMESTEP_COUNT+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies = np.arange(TOTAL_DATA_NUM,dtype='uint64')\n",
    "np.random.shuffle(indicies)\n",
    "df_as_frames=df_as_frames[indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 0\n",
      " 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1\n",
      " 1 0 1 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0\n",
      " 0 1 1 0 0 1 0 0 0]\n",
      "[0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# convert the data into inputs and outputs\n",
    "y = df_as_frames[:,-1,:]\n",
    "X = df_as_frames[:,:-1,]\n",
    "X = X.reshape([X.shape[0], X.shape[1]*X.shape[2]])\n",
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into train and test data\n",
    "X_train = X[TEST_COUNT:]\n",
    "X_test = X[:TEST_COUNT]\n",
    "y_train = y[TEST_COUNT:]\n",
    "y_test = y[:TEST_COUNT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\tLOSS=\"binary_crossentropy\"\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(2000, activation='relu',input_shape=[X.shape[1]] ))\n",
    "\tmodel.add(Dense(1024, activation='relu'))\n",
    "\tmodel.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "\topt = keras.optimizers.Nadam(\n",
    "\t\tlearning_rate=hp.Float(\"learning_rate\", 10**(-5), 10**(-3),sampling=\"log\"),\n",
    "\t\tepsilon=hp.Float(\"epsilon\",1e-7,1e-5,sampling=\"log\"),\n",
    "\t\tbeta_1=hp.Float(\"beta_1\",.8,.9,sampling=\"reverse_log\"),\n",
    "\t\tbeta_2=hp.Float(\"beta_2\",.8,.9,sampling=\"reverse_log\"),\n",
    "\t\t)\n",
    "\tmodel.compile(optimizer=opt, loss=LOSS,metrics=['binary_accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define call back functions\n",
    "stopEarly = tf.keras.callbacks.EarlyStopping(\n",
    "\tmonitor='binary_accuracy', min_delta=.001, patience=3, verbose=0, mode='auto', restore_best_weights=False\n",
    ")\n",
    "\n",
    "log_dir = \"hyperparameters/\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,profile_batch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a short set from the training for hyper parameter tuning\n",
    "X_train_short= X_train[:600000]\n",
    "y_train_short= y_train[:600000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [01h 59m 53s]\n",
      "binary_accuracy: 0.6121696829795837\n",
      "\n",
      "Best binary_accuracy So Far: 0.7467892169952393\n",
      "Total elapsed time: 09h 36m 42s\n",
      "\n",
      "Search: Running Trial #4\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.00016481        |0.0001871         |learning_rate\n",
      "5.2127e-07        |1.1351e-06        |epsilon\n",
      "0.86233           |0.88728           |beta_1\n",
      "0.81789           |0.88328           |beta_2\n",
      "\n",
      "Epoch 1/100\n",
      "2344/2344 [==============================] - 203s 86ms/step - loss: 0.6024 - binary_accuracy: 0.5749 - val_loss: 0.5959 - val_binary_accuracy: 0.5776\n",
      "Epoch 2/100\n",
      "2344/2344 [==============================] - 199s 85ms/step - loss: 0.5954 - binary_accuracy: 0.5808 - val_loss: 0.5953 - val_binary_accuracy: 0.5770\n",
      "Epoch 3/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.5945 - binary_accuracy: 0.5869 - val_loss: 0.5954 - val_binary_accuracy: 0.5775\n",
      "Epoch 4/100\n",
      "2344/2344 [==============================] - 199s 85ms/step - loss: 0.5937 - binary_accuracy: 0.5929 - val_loss: 0.5956 - val_binary_accuracy: 0.5777\n",
      "Epoch 5/100\n",
      "2344/2344 [==============================] - 200s 85ms/step - loss: 0.5926 - binary_accuracy: 0.5991 - val_loss: 0.5960 - val_binary_accuracy: 0.5771\n",
      "Epoch 6/100\n",
      "2344/2344 [==============================] - 214s 91ms/step - loss: 0.5914 - binary_accuracy: 0.6051 - val_loss: 0.5965 - val_binary_accuracy: 0.5780\n",
      "Epoch 7/100\n",
      "2344/2344 [==============================] - 221s 94ms/step - loss: 0.5899 - binary_accuracy: 0.6106 - val_loss: 0.5975 - val_binary_accuracy: 0.5763\n",
      "Epoch 8/100\n",
      "2344/2344 [==============================] - 206s 88ms/step - loss: 0.5882 - binary_accuracy: 0.6163 - val_loss: 0.5984 - val_binary_accuracy: 0.5762\n",
      "Epoch 9/100\n",
      "2344/2344 [==============================] - 203s 86ms/step - loss: 0.5864 - binary_accuracy: 0.6216 - val_loss: 0.5997 - val_binary_accuracy: 0.5765\n",
      "Epoch 10/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.5844 - binary_accuracy: 0.6268 - val_loss: 0.6009 - val_binary_accuracy: 0.5748\n",
      "Epoch 11/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.5823 - binary_accuracy: 0.6320 - val_loss: 0.6023 - val_binary_accuracy: 0.5756\n",
      "Epoch 12/100\n",
      "2344/2344 [==============================] - 203s 86ms/step - loss: 0.5801 - binary_accuracy: 0.6369 - val_loss: 0.6037 - val_binary_accuracy: 0.5751\n",
      "Epoch 13/100\n",
      "2344/2344 [==============================] - 207s 88ms/step - loss: 0.5777 - binary_accuracy: 0.6417 - val_loss: 0.6056 - val_binary_accuracy: 0.5744\n",
      "Epoch 14/100\n",
      "2344/2344 [==============================] - 204s 87ms/step - loss: 0.5753 - binary_accuracy: 0.6463 - val_loss: 0.6075 - val_binary_accuracy: 0.5740\n",
      "Epoch 15/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.5729 - binary_accuracy: 0.6507 - val_loss: 0.6093 - val_binary_accuracy: 0.5733\n",
      "Epoch 16/100\n",
      "2344/2344 [==============================] - 203s 87ms/step - loss: 0.5704 - binary_accuracy: 0.6549 - val_loss: 0.6111 - val_binary_accuracy: 0.5742\n",
      "Epoch 17/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.5678 - binary_accuracy: 0.6590 - val_loss: 0.6134 - val_binary_accuracy: 0.5735\n",
      "Epoch 18/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.5653 - binary_accuracy: 0.6629 - val_loss: 0.6155 - val_binary_accuracy: 0.5741\n",
      "Epoch 19/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.5628 - binary_accuracy: 0.6667 - val_loss: 0.6180 - val_binary_accuracy: 0.5740\n",
      "Epoch 20/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.5603 - binary_accuracy: 0.6701 - val_loss: 0.6201 - val_binary_accuracy: 0.5737\n",
      "Epoch 21/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.5578 - binary_accuracy: 0.6734 - val_loss: 0.6225 - val_binary_accuracy: 0.5731\n",
      "Epoch 22/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.5554 - binary_accuracy: 0.6767 - val_loss: 0.6246 - val_binary_accuracy: 0.5740\n",
      "Epoch 23/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.5531 - binary_accuracy: 0.6796 - val_loss: 0.6275 - val_binary_accuracy: 0.5743\n",
      "Epoch 24/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.5508 - binary_accuracy: 0.6824 - val_loss: 0.6301 - val_binary_accuracy: 0.5739\n",
      "Epoch 25/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.5486 - binary_accuracy: 0.6851 - val_loss: 0.6327 - val_binary_accuracy: 0.5737\n",
      "Epoch 26/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.5464 - binary_accuracy: 0.6876 - val_loss: 0.6355 - val_binary_accuracy: 0.5732\n",
      "Epoch 27/100\n",
      "2344/2344 [==============================] - 200s 85ms/step - loss: 0.5443 - binary_accuracy: 0.6901 - val_loss: 0.6380 - val_binary_accuracy: 0.5731\n",
      "Epoch 28/100\n",
      "2344/2344 [==============================] - 205s 88ms/step - loss: 0.5423 - binary_accuracy: 0.6924 - val_loss: 0.6406 - val_binary_accuracy: 0.5743\n",
      "Epoch 29/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.5403 - binary_accuracy: 0.6946 - val_loss: 0.6435 - val_binary_accuracy: 0.5727\n",
      "Epoch 30/100\n",
      "2344/2344 [==============================] - 200s 85ms/step - loss: 0.5385 - binary_accuracy: 0.6967 - val_loss: 0.6457 - val_binary_accuracy: 0.5727\n",
      "Epoch 31/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.5367 - binary_accuracy: 0.6985 - val_loss: 0.6486 - val_binary_accuracy: 0.5726\n",
      "Epoch 32/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.5349 - binary_accuracy: 0.7005 - val_loss: 0.6513 - val_binary_accuracy: 0.5732\n",
      "Epoch 33/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.5332 - binary_accuracy: 0.7023 - val_loss: 0.6538 - val_binary_accuracy: 0.5732\n",
      "Epoch 34/100\n",
      "2344/2344 [==============================] - 205s 88ms/step - loss: 0.5316 - binary_accuracy: 0.7041 - val_loss: 0.6560 - val_binary_accuracy: 0.5735\n",
      "Epoch 35/100\n",
      "2344/2344 [==============================] - 203s 87ms/step - loss: 0.5300 - binary_accuracy: 0.7056 - val_loss: 0.6582 - val_binary_accuracy: 0.5738\n",
      "Epoch 36/100\n",
      "2344/2344 [==============================] - 204s 87ms/step - loss: 0.5284 - binary_accuracy: 0.7073 - val_loss: 0.6614 - val_binary_accuracy: 0.5743\n",
      "Epoch 37/100\n",
      "2344/2344 [==============================] - 204s 87ms/step - loss: 0.5269 - binary_accuracy: 0.7088 - val_loss: 0.6634 - val_binary_accuracy: 0.5734\n",
      "Epoch 38/100\n",
      "2344/2344 [==============================] - 203s 87ms/step - loss: 0.5255 - binary_accuracy: 0.7102 - val_loss: 0.6661 - val_binary_accuracy: 0.5729\n",
      "Epoch 39/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.5241 - binary_accuracy: 0.7114 - val_loss: 0.6679 - val_binary_accuracy: 0.5735\n",
      "Epoch 40/100\n",
      "2344/2344 [==============================] - 211s 90ms/step - loss: 0.5228 - binary_accuracy: 0.7128 - val_loss: 0.6702 - val_binary_accuracy: 0.5739\n",
      "Epoch 41/100\n",
      "2344/2344 [==============================] - 207s 88ms/step - loss: 0.5215 - binary_accuracy: 0.7141 - val_loss: 0.6731 - val_binary_accuracy: 0.5730\n",
      "Epoch 42/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.5202 - binary_accuracy: 0.7153 - val_loss: 0.6756 - val_binary_accuracy: 0.5740\n",
      "Epoch 43/100\n",
      "2344/2344 [==============================] - 200s 85ms/step - loss: 0.5190 - binary_accuracy: 0.7165 - val_loss: 0.6770 - val_binary_accuracy: 0.5735\n",
      "Epoch 44/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.5179 - binary_accuracy: 0.7177 - val_loss: 0.6797 - val_binary_accuracy: 0.5726\n",
      "Epoch 45/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.5167 - binary_accuracy: 0.7186 - val_loss: 0.6815 - val_binary_accuracy: 0.5738\n",
      "Epoch 46/100\n",
      "2344/2344 [==============================] - 207s 88ms/step - loss: 0.5106 - binary_accuracy: 0.7243 - val_loss: 0.6935 - val_binary_accuracy: 0.5734\n",
      "Epoch 52/100\n",
      "2344/2344 [==============================] - 207s 88ms/step - loss: 0.5097 - binary_accuracy: 0.7253 - val_loss: 0.6959 - val_binary_accuracy: 0.5735\n",
      "Epoch 53/100\n",
      "2344/2344 [==============================] - 250s 107ms/step - loss: 0.5088 - binary_accuracy: 0.7261 - val_loss: 0.6970 - val_binary_accuracy: 0.5733\n",
      "Epoch 54/100\n",
      "2344/2344 [==============================] - 223s 95ms/step - loss: 0.5079 - binary_accuracy: 0.7269 - val_loss: 0.6989 - val_binary_accuracy: 0.5734\n",
      "Epoch 55/100\n",
      "2344/2344 [==============================] - 203s 87ms/step - loss: 0.5071 - binary_accuracy: 0.7276 - val_loss: 0.7010 - val_binary_accuracy: 0.5726\n",
      "Epoch 56/100\n",
      "2344/2344 [==============================] - 203s 87ms/step - loss: 0.5062 - binary_accuracy: 0.7285 - val_loss: 0.7025 - val_binary_accuracy: 0.5735\n",
      "Epoch 57/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.5054 - binary_accuracy: 0.7291 - val_loss: 0.7044 - val_binary_accuracy: 0.5731\n",
      "Epoch 58/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.5046 - binary_accuracy: 0.7298 - val_loss: 0.7059 - val_binary_accuracy: 0.5730\n",
      "Epoch 59/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.5039 - binary_accuracy: 0.7305 - val_loss: 0.7071 - val_binary_accuracy: 0.5729\n",
      "Epoch 60/100\n",
      "2344/2344 [==============================] - 203s 86ms/step - loss: 0.5032 - binary_accuracy: 0.7311 - val_loss: 0.7096 - val_binary_accuracy: 0.5732\n",
      "Epoch 61/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.5024 - binary_accuracy: 0.7318 - val_loss: 0.7109 - val_binary_accuracy: 0.5728\n",
      "Epoch 62/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.5017 - binary_accuracy: 0.7324 - val_loss: 0.7122 - val_binary_accuracy: 0.5737\n",
      "Epoch 63/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.5010 - binary_accuracy: 0.7329 - val_loss: 0.7139 - val_binary_accuracy: 0.5733\n",
      "Epoch 64/100\n",
      "2344/2344 [==============================] - 203s 87ms/step - loss: 0.5004 - binary_accuracy: 0.7335 - val_loss: 0.7161 - val_binary_accuracy: 0.5730\n",
      "Epoch 65/100\n",
      "2344/2344 [==============================] - 203s 87ms/step - loss: 0.4997 - binary_accuracy: 0.7341 - val_loss: 0.7166 - val_binary_accuracy: 0.5726\n",
      "Epoch 66/100\n",
      "2344/2344 [==============================] - 206s 88ms/step - loss: 0.4991 - binary_accuracy: 0.7347 - val_loss: 0.7184 - val_binary_accuracy: 0.5725\n",
      "Epoch 67/100\n",
      "2344/2344 [==============================] - 204s 87ms/step - loss: 0.4984 - binary_accuracy: 0.7353 - val_loss: 0.7197 - val_binary_accuracy: 0.5734\n",
      "Epoch 68/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.4978 - binary_accuracy: 0.7358 - val_loss: 0.7211 - val_binary_accuracy: 0.5726\n",
      "Epoch 69/100\n",
      "2344/2344 [==============================] - 204s 87ms/step - loss: 0.4972 - binary_accuracy: 0.7363 - val_loss: 0.7231 - val_binary_accuracy: 0.5729\n",
      "Epoch 70/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.4966 - binary_accuracy: 0.7368 - val_loss: 0.7243 - val_binary_accuracy: 0.5732\n",
      "Epoch 71/100\n",
      "2344/2344 [==============================] - 203s 86ms/step - loss: 0.4961 - binary_accuracy: 0.7373 - val_loss: 0.7255 - val_binary_accuracy: 0.5731\n",
      "Epoch 72/100\n",
      "2344/2344 [==============================] - 203s 86ms/step - loss: 0.4955 - binary_accuracy: 0.7378 - val_loss: 0.7267 - val_binary_accuracy: 0.5731\n",
      "Epoch 73/100\n",
      "2344/2344 [==============================] - 200s 86ms/step - loss: 0.4949 - binary_accuracy: 0.7382 - val_loss: 0.7283 - val_binary_accuracy: 0.5729\n",
      "Epoch 74/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.4944 - binary_accuracy: 0.7386 - val_loss: 0.7294 - val_binary_accuracy: 0.5727\n",
      "Epoch 75/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.4939 - binary_accuracy: 0.7392 - val_loss: 0.7308 - val_binary_accuracy: 0.5726\n",
      "Epoch 76/100\n",
      "2344/2344 [==============================] - 203s 86ms/step - loss: 0.4934 - binary_accuracy: 0.7396 - val_loss: 0.7311 - val_binary_accuracy: 0.5730\n",
      "Epoch 77/100\n",
      "2344/2344 [==============================] - 203s 87ms/step - loss: 0.4929 - binary_accuracy: 0.7399 - val_loss: 0.7333 - val_binary_accuracy: 0.5729\n",
      "Epoch 78/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.4924 - binary_accuracy: 0.7404 - val_loss: 0.7339 - val_binary_accuracy: 0.5730\n",
      "Epoch 79/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.4919 - binary_accuracy: 0.7407 - val_loss: 0.7358 - val_binary_accuracy: 0.5729\n",
      "Epoch 80/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.4914 - binary_accuracy: 0.7413 - val_loss: 0.7369 - val_binary_accuracy: 0.5727\n",
      "Epoch 81/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.4909 - binary_accuracy: 0.7417 - val_loss: 0.7379 - val_binary_accuracy: 0.5733\n",
      "Epoch 82/100\n",
      "2344/2344 [==============================] - 202s 86ms/step - loss: 0.4905 - binary_accuracy: 0.7421 - val_loss: 0.7392 - val_binary_accuracy: 0.5722\n",
      "Epoch 83/100\n",
      "2344/2344 [==============================] - 203s 87ms/step - loss: 0.4901 - binary_accuracy: 0.7423 - val_loss: 0.7412 - val_binary_accuracy: 0.5720\n",
      "Epoch 84/100\n",
      "2344/2344 [==============================] - 203s 87ms/step - loss: 0.4896 - binary_accuracy: 0.7427 - val_loss: 0.7411 - val_binary_accuracy: 0.5728\n",
      "Epoch 85/100\n",
      "2344/2344 [==============================] - 207s 88ms/step - loss: 0.4892 - binary_accuracy: 0.7431 - val_loss: 0.7428 - val_binary_accuracy: 0.5719\n",
      "Epoch 86/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.4888 - binary_accuracy: 0.7434 - val_loss: 0.7435 - val_binary_accuracy: 0.5720\n",
      "Epoch 87/100\n",
      "2344/2344 [==============================] - 204s 87ms/step - loss: 0.4884 - binary_accuracy: 0.7438 - val_loss: 0.7451 - val_binary_accuracy: 0.5727\n",
      "Epoch 88/100\n",
      "2344/2344 [==============================] - 201s 86ms/step - loss: 0.4879 - binary_accuracy: 0.7440 - val_loss: 0.7454 - val_binary_accuracy: 0.5730\n",
      "Epoch 89/100\n",
      "  91/2344 [>.............................] - ETA: 3:12 - loss: 0.4768 - binary_accuracy: 0.7541"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tuning the hyper parameters\n",
    "\n",
    "tuner = kt.tuners.bayesian.BayesianOptimization(build_model,'binary_accuracy',20,project_name=\"bayes\", seed=myrand)\n",
    "tuner.search(X_train_short, y_train_short,batch_size=256, epochs=100, validation_data=(X_test,y_test),callbacks=[stopEarly,tensorboard_callback])\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.00035495571278655694,\n",
       " 'epsilon': 1e-05,\n",
       " 'beta_1': 0.8516826262117726,\n",
       " 'beta_2': 0.8000000000000002}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "# use the best model for training\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X = X_train, Y=y_train, epochs=10, batch_size=512,verbose=0, log_dir = f\"dense_model/\"):\n",
    "    log_dir += datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,profile_batch=0)\n",
    "    model.fit(X, Y, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size,callbacks=[tensorboard_callback],verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "my_model_trained = train_model(model, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 14ms/step - loss: 0.6007 - binary_accuracy: 0.5762\n",
      "test loss: 0.600691, test acc: 0.5761699676513672\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, batch_size=256)\n",
    "print(\"test loss: %f, test acc: %s\" % tuple(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_trained.save(\"hashdice_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
