{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup configuration for our validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "HD_OUTPUT_FILENAME = 'hashdice_validation.txt'\n",
    "PREVIOUS_TIMESTEP_COUNT = 4\n",
    "IMPORT_COUNT = 100000 + PREVIOUS_TIMESTEP_COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate deterministic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hmac\n",
    "import hashlib\n",
    "\n",
    "def hashdice(secret_key, message):\n",
    "    hmac_sha512 = hmac.new(key=secret_key.encode(), msg=message.encode(), digestmod=hashlib.sha512).hexdigest()\n",
    "    lucky = int(hmac_sha512[0:5], 16)\n",
    "    return lucky % 100000\n",
    "\n",
    "\n",
    "with open(HD_OUTPUT_FILENAME, 'w') as f:\n",
    "\n",
    "    for i in range(IMPORT_COUNT + 1):\n",
    "        secret_key = '4671f003b18db91be8f1570c7f681ad9e97026c5f34d89a733f48ab81eb8d592'\n",
    "        message = f'5533idsczGPRYacG5N15jfJ6nm5:{i}'\n",
    "        result = hashdice(secret_key, message)\n",
    "        rs = str(result)\n",
    "        f.write(f'{rs + str(i%10000)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to input and target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "(100001, 120) (100001, 30)\n",
      "[0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0\n",
      " 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "[0 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# convert the sequence of generated numbers to 4 inputs and one output\n",
    "def strided(a, L):\n",
    "    shp = a.shape\n",
    "    s  = a.strides\n",
    "    nd0 = shp[0]-L+1\n",
    "    shp_in = (nd0,L)+shp[1:]\n",
    "    strd_in = (s[0],) + s\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shp_in, strides=strd_in)\n",
    "\n",
    "df = np.genfromtxt(HD_OUTPUT_FILENAME,delimiter='\\n',dtype='uint64')\n",
    "TOTAL_DATA_NUM = IMPORT_COUNT-PREVIOUS_TIMESTEP_COUNT\n",
    "\n",
    "# calculates how many bits are in the output.\n",
    "BIT_WIDTH = np.ceil(np.log2(np.amax(df))).astype(int)\n",
    "print(BIT_WIDTH)\n",
    "# convert the generated numbers to binary sequences\n",
    "df_as_bits =(df[:,None] & (1 << np.arange(BIT_WIDTH,dtype='uint64')) > 0).astype(int)\n",
    "df_as_frames = strided(df_as_bits, PREVIOUS_TIMESTEP_COUNT+1)\n",
    "\n",
    "#indicies = np.arange(TOTAL_DATA_NUM,dtype='uint64')\n",
    "#print(indicies)\n",
    "#np.random.shuffle(indicies)\n",
    "#print(indicies)\n",
    "#df_as_frames=df_as_frames[indicies]\n",
    "\n",
    "# convert the data into inputs and outputs\n",
    "y = df_as_frames[:,-1,:]\n",
    "X = df_as_frames[:,:-1,]\n",
    "X = X.reshape([X.shape[0], X.shape[1]*X.shape[2]])\n",
    "\n",
    "print(np.shape(X), np.shape(y))\n",
    "\n",
    "\n",
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('hashdice_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate bitwise accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 4ms/step - loss: 0.5893 - binary_accuracy: 0.6081\n",
      "test loss: 0.589338, test acc: 0.608125627040863\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X, y, batch_size=256)\n",
    "print(\"test loss: %f, test acc: %s\" % tuple(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "Original Result 2.1703588e-08, 0.7316017, 0.81323016, 0.9431137, 0.4095405, 0.34946904, 0.35475978, 0.4875862, 0.29990268, 0.2936106, 0.46594527, 0.6648567, 0.64295185, 0.19875206, 0.48983806, 0.5256254, 0.50200075, 0.655248, 0.25556362, 0.84801924, 0.11043845, 0.016831614, 0.035998885, 0.20185827, 0.002463287, 0.0019066184, 0.005732572, 1.1864399e-06, 1.505222e-06, 1.3652289e-05\n",
      "-------------------------\n",
      "Original Result 1.3652289e-05, 1.505222e-06, 1.1864399e-06, 0.005732572, 0.0019066184, 0.002463287, 0.20185827, 0.035998885, 0.016831614, 0.11043845, 0.84801924, 0.25556362, 0.655248, 0.50200075, 0.5256254, 0.48983806, 0.19875206, 0.64295185, 0.6648567, 0.46594527, 0.2936106, 0.29990268, 0.4875862, 0.35475978, 0.34946904, 0.4095405, 0.9431137, 0.81323016, 0.7316017, 2.1703588e-08\n",
      "reverse correct output------------[0 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "predicted output reverse----------[0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "correct output--------------------[0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1 0]\n",
      "predicted output------------------[0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0]\n",
      "correct output--------------------907918\n",
      "predicted output------------------759822.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "index = 4\n",
    "inputTest=np.reshape(X[index],(1,120))\n",
    "predict = model.predict(inputTest)\n",
    "\n",
    "\n",
    "orignalResult = ', '.join([str(x) for x in predict[0]])\n",
    "print(f'Original Result {orignalResult}')\n",
    "orignalResult = ', '.join([str(x) for x in predict[0][::-1]])\n",
    "print(f'-------------------------')\n",
    "print(f'Original Result {orignalResult}')\n",
    "npWhere=np.where(predict[0] > 0.5, 1, 0)\n",
    "print(f'reverse correct output------------{y[index]}')\n",
    "print(f'predicted output reverse----------{npWhere}')\n",
    "o = y[index][::-1]\n",
    "print(f'correct output--------------------{o}')\n",
    "npWhere = npWhere[::-1]\n",
    "print(f'predicted output------------------{npWhere}')\n",
    "tfround = tf.round(predict[0])\n",
    "#print(f'tfround {tfround}')\n",
    "\n",
    "output = sum(bit * 2**(len(o)-i-1) for i, bit in enumerate(o))\n",
    "print(f'correct output--------------------{output}')\n",
    "result = np.array(tfround[::-1])\n",
    "result = sum(bit * 2**(len(result)-i-1) for i, bit in enumerate(result))\n",
    "print(f'predicted output------------------{result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#000000000011010100001101001010\n",
    "#000000000001101001101101001110"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26adf6824cc28eec5712fda69f7f12e89b06b885262dbddff658e7fce52ab42f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
